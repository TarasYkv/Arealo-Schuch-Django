# VOLLST√ÑNDIGER CODE F√úR: pdf_sucher/views.py

import os
import io
from datetime import datetime

import fitz  # PyMuPDF
import openai
import numpy as np
from PIL import Image
from django.conf import settings
from django.core.files.storage import FileSystemStorage
from django.http import FileResponse, Http404, HttpResponse
from django.shortcuts import render
from werkzeug.utils import secure_filename

# Setzen des OpenAI API-Schl√ºssels
openai.api_key = settings.OPENAI_API_KEY


def cosine_similarity(v1, v2):
    """Berechnet die Kosinus-√Ñhnlichkeit zwischen zwei Vektoren."""
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))


def expand_search_terms_with_ai(query, perspective="sales"):
    """Erweitert Suchbegriffe mit KI um verwandte und interessante Begriffe zu finden."""
    try:
        # Definiere perspektivspezifische Prompts
        if perspective == "sales":
            role_context = """
            Du bist ein erfahrener Vertriebsmitarbeiter eines Leuchtenherstellers.
            Erweitere die Suchanfrage um Begriffe, die f√ºr den Vertrieb wichtig sind:
            - Produkteigenschaften und Verkaufsargumente
            - Preise, Konditionen und Lieferbedingungen
            - Zertifizierungen und Qualit√§tsstandards
            - Kundenanforderungen und Anwendungsbereiche
            - Marktpositionierung und Wettbewerbsvorteile
            
            Beispiel f√ºr "LED Beleuchtung":
            LED, Beleuchtung, Leuchte, Preis, Kosten, Energieeffizienz, Garantie, Lieferzeit, CE-Kennzeichnung, Anwendung, Einsatzbereich, Wartung
            """
        else:  # technical
            role_context = """
            Du bist ein erfahrener Entwickler/Techniker eines Leuchtenherstellers.
            Erweitere die Suchanfrage um Begriffe, die f√ºr die technische Entwicklung wichtig sind:
            - Detaillierte technische Spezifikationen
            - Normen, Standards und Vorschriften
            - Installationsdetails und Montageanforderungen
            - Elektrische Parameter und Schaltpl√§ne
            - Materialien und technische Umsetzung
            
            Beispiel f√ºr "LED Beleuchtung":
            LED, Spannung, Strom, Leistung, Lumen, Kelvin, CRI, IP-Schutzart, IK-Schutzklasse, DIN, EN, VDE, Schaltplan, Anschluss, Kabel
            """

        expansion_prompt = f"""
        {role_context}

        Urspr√ºngliche Anfrage: "{query}"

        WICHTIG: Erweitere NUR um Begriffe, die thematisch eng verwandt mit der urspr√ºnglichen Anfrage sind.
        - Verwende Synonyme und Fachbegriffe der urspr√ºnglichen Begriffe
        - F√ºge KEINE allgemeinen Beleuchtungsbegriffe hinzu, wenn sie nicht zum Kontext passen
        - Konzentriere dich auf die spezifische Bedeutung der Anfrage
        - Wenn die Anfrage sehr spezifisch ist, erweitere nur minimal

        Gib eine kommaseparierte Liste von 12-15 eng verwandten Suchbegriffen zur√ºck.

        Erweiterte Begriffe f√ºr "{query}":
        """
        
        print(f"DEBUG: Sende OpenAI-Anfrage f√ºr '{query}' mit Perspektive '{perspective}'")
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": expansion_prompt}],
            max_tokens=200,
            temperature=0.3
        )
        print(f"DEBUG: OpenAI-Antwort erhalten")
        
        expanded_terms = response.choices[0].message.content.strip()
        # Bereinige und splitte die Begriffe
        terms = [term.strip() for term in expanded_terms.split(',') if term.strip()]
        
        print(f"DEBUG: Erweiterte Suchbegriffe ({perspective}): {terms}")
        return terms
        
    except Exception as e:
        print(f"FEHLER bei der Begriffserweiterung: {e}")
        # Fallback: Verwende urspr√ºngliche Query-Begriffe
        fallback_terms = [term.strip() for term in query.split() if len(term.strip()) > 1]
        print(f"DEBUG: Fallback zu urspr√ºnglichen Begriffen: {fallback_terms}")
        return fallback_terms


def perform_semantic_search(pdf_path, query, page_range, strictness_threshold, perspective="sales"):
    """F√ºhrt eine KI-gest√ºtzte Suche durch, die verwandte Begriffe findet und danach sucht."""
    ergebnisse = []
    try:
        doc = fitz.open(pdf_path)
        start_page, end_page = page_range

        # 1. Erweitere Suchbegriffe mit KI basierend auf der gew√§hlten Perspektive
        expanded_search_terms = expand_search_terms_with_ai(query, perspective)
        original_query_terms = [term.strip() for term in query.split() if len(term.strip()) > 1]
        
        # Falls KI-Erweiterung fehlschl√§gt, verwende nur urspr√ºngliche Begriffe
        if not expanded_search_terms:
            expanded_search_terms = original_query_terms.copy()
            print(f"DEBUG: KI-Erweiterung fehlgeschlagen, verwende nur urspr√ºngliche Begriffe: {expanded_search_terms}")
        
        print(f"DEBUG: Original-Begriffe: {original_query_terms}")
        print(f"DEBUG: Erweiterte Begriffe: {expanded_search_terms}")
        
        # 2. Durchsuche alle Seiten nach den erweiterten Begriffen
        for page_num in range(start_page, end_page):
            page = doc.load_page(page_num)
            text = page.get_text("text")
            if not text.strip():
                continue
                
            # Finde alle Begriffe auf dieser Seite
            found_terms = []
            original_found = []
            extended_found = []
            
            for term in expanded_search_terms:
                if term.lower() in text.lower():
                    found_terms.append(term)
                    # Klassifiziere: Original oder erweitert?
                    if any(orig_term.lower() == term.lower() or orig_term.lower() in term.lower() or term.lower() in orig_term.lower() 
                           for orig_term in original_query_terms):
                        original_found.append(term)
                    else:
                        extended_found.append(term)
            
            if found_terms:
                # 3. Berechne Relevanz basierend auf Strenge-Einstellung
                # Strenge = wie wichtig urspr√ºngliche vs. erweiterte Begriffe sind
                original_weight = strictness_threshold  # 0.1 = wenig streng, 0.8 = sehr streng
                extended_weight = 1 - strictness_threshold
                
                # Score basierend auf gefundenen Original- und erweiterten Begriffen
                original_score = len(original_found) / max(len(original_query_terms), 1) * original_weight
                extended_score = len(extended_found) / max(len(expanded_search_terms) - len(original_query_terms), 1) * extended_weight
                
                relevance_score = original_score + extended_score
                
                # Jede Seite mit gefundenen Begriffen wird angezeigt
                if True:  # Tempor√§r: Zeige alle Fundstellen
                    print(f"DEBUG: Seite {page_num + 1}")
                    print(f"  Original gefunden: {original_found} (Score: {original_score:.3f})")
                    print(f"  Erweitert gefunden: {extended_found} (Score: {extended_score:.3f})")
                    print(f"  Gesamt-Relevanz: {relevance_score:.3f}")
                    
                    # Extrahiere relevanten Kontext
                    context_snippet = extract_context_around_terms(text, found_terms, max_lines=9)
                    highlighted_snippet = highlight_terms_in_text(context_snippet, found_terms, original_query_terms)
                    
                    ergebnisse.append({
                        'seitenzahl': page_num + 1,
                        'textstelle': context_snippet,
                        'textstelle_highlighted': highlighted_snippet,
                        'relevance_score': relevance_score,
                        'found_terms': found_terms,
                        'original_found': original_found,
                        'extended_found': extended_found
                    })
        
        doc.close()
        
        # 4. Sortiere nach Relevanz und wende Strenge-Filter an
        ergebnisse.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        print(f"DEBUG: {len(ergebnisse)} Gesamtergebnisse gefunden")
        if ergebnisse:
            print("DEBUG: Top Relevanz-Scores:", [round(r['relevance_score'], 3) for r in ergebnisse[:5]])
        
        # Wende Strenge-basierte Filterung an
        if ergebnisse:
            # Bei Strenge > 0.5: Nur Ergebnisse mit urspr√ºnglichen Begriffen
            if strictness_threshold > 0.5:
                strict_results = [r for r in ergebnisse if r.get('original_found', [])]
                if strict_results:
                    print(f"DEBUG: Strenge Filterung: {len(strict_results)} von {len(ergebnisse)} Ergebnissen (nur mit urspr√ºnglichen Begriffen)")
                    return strict_results
                else:
                    print(f"DEBUG: Strenge Filterung ergab keine Ergebnisse - zeige beste 3")
                    return ergebnisse[:3]
            else:
                # Bei niedriger Strenge: Alle Ergebnisse
                print(f"DEBUG: Lockere Filterung: Zeige alle {len(ergebnisse)} gefundenen Ergebnisse")
                return ergebnisse
        else:
            print("DEBUG: Keine Ergebnisse gefunden")
            return []

    except Exception as e:
        print(f"FEHLER bei der semantischen Suche: {e}")
        return []


def perform_semantic_search_with_selected_terms(pdf_path, query, page_range, strictness_threshold, perspective="sales", selected_expanded_terms=None):
    """F√ºhrt eine KI-gest√ºtzte Suche durch mit vorausgew√§hlten erweiterten Begriffen."""
    ergebnisse = []
    try:
        doc = fitz.open(pdf_path)
        start_page, end_page = page_range

        # 1. Verwende urspr√ºngliche Begriffe plus ausgew√§hlte erweiterte Begriffe
        original_query_terms = [term.strip() for term in query.split() if len(term.strip()) > 1]
        
        # Kombiniere urspr√ºngliche und ausgew√§hlte erweiterte Begriffe
        if selected_expanded_terms:
            all_search_terms = original_query_terms + selected_expanded_terms
        else:
            # Fallback: Verwende automatisch generierte erweiterte Begriffe wenn keine ausgew√§hlt wurden
            expanded_search_terms = expand_search_terms_with_ai(query, perspective)
            all_search_terms = original_query_terms + expanded_search_terms
        
        print(f"DEBUG: Original-Begriffe: {original_query_terms}")
        print(f"DEBUG: Alle Suchbegriffe: {all_search_terms}")
        
        # 2. Durchsuche alle Seiten nach den kombinierten Begriffen
        for page_num in range(start_page, end_page):
            page = doc.load_page(page_num)
            text = page.get_text("text")
            if not text.strip():
                continue
                
            # Finde alle Begriffe auf dieser Seite
            found_terms = []
            original_found = []
            extended_found = []
            
            for term in all_search_terms:
                if term.lower() in text.lower():
                    found_terms.append(term)
                    # Klassifiziere: Original oder erweitert?
                    if any(orig_term.lower() == term.lower() or orig_term.lower() in term.lower() or term.lower() in orig_term.lower() 
                           for orig_term in original_query_terms):
                        original_found.append(term)
                    else:
                        extended_found.append(term)
            
            if found_terms:
                # 3. Berechne Relevanz basierend auf Strenge-Einstellung
                original_weight = strictness_threshold
                extended_weight = 1 - strictness_threshold
                
                # Score basierend auf gefundenen Original- und erweiterten Begriffen
                original_score = len(original_found) / max(len(original_query_terms), 1) * original_weight
                extended_score = len(extended_found) / max(len(all_search_terms) - len(original_query_terms), 1) * extended_weight
                
                relevance_score = original_score + extended_score
                
                print(f"DEBUG: Seite {page_num + 1}")
                print(f"  Original gefunden: {original_found} (Score: {original_score:.3f})")
                print(f"  Erweitert gefunden: {extended_found} (Score: {extended_score:.3f})")
                print(f"  Gesamt-Relevanz: {relevance_score:.3f}")
                
                # Extrahiere relevanten Kontext
                context_snippet = extract_context_around_terms(text, found_terms, max_lines=9)
                highlighted_snippet = highlight_terms_in_text(context_snippet, found_terms, original_query_terms)
                
                ergebnisse.append({
                    'seitenzahl': page_num + 1,
                    'textstelle': context_snippet,
                    'textstelle_highlighted': highlighted_snippet,
                    'relevance_score': relevance_score,
                    'found_terms': found_terms,
                    'original_found': original_found,
                    'extended_found': extended_found
                })
        
        doc.close()
        
        # 4. Sortiere nach Relevanz und wende Strenge-Filter an
        ergebnisse.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        print(f"DEBUG: {len(ergebnisse)} Gesamtergebnisse gefunden")
        if ergebnisse:
            print("DEBUG: Top Relevanz-Scores:", [round(r['relevance_score'], 3) for r in ergebnisse[:5]])
        
        # Wende Strenge-basierte Filterung an
        if ergebnisse:
            if strictness_threshold > 0.5:
                strict_results = [r for r in ergebnisse if r.get('original_found', [])]
                if strict_results:
                    print(f"DEBUG: Strenge Filterung: {len(strict_results)} von {len(ergebnisse)} Ergebnissen")
                    return strict_results
                else:
                    print(f"DEBUG: Strenge Filterung ergab keine Ergebnisse - zeige beste 3")
                    return ergebnisse[:3]
            else:
                print(f"DEBUG: Lockere Filterung: Zeige alle {len(ergebnisse)} gefundenen Ergebnisse")
                return ergebnisse
        else:
            print("DEBUG: Keine Ergebnisse gefunden")
            return []

    except Exception as e:
        print(f"FEHLER bei der semantischen Suche mit ausgew√§hlten Begriffen: {e}")
        return []


def highlight_terms_in_text(text, search_terms, original_query_terms=None):
    """Hebt Suchbegriffe im Text farblich hervor."""
    import re
    highlighted_text = text
    
    # Bestimme welche Begriffe urspr√ºnglich sind und welche KI-erweitert
    if original_query_terms is None:
        original_query_terms = []
    
    # Sortiere Suchbegriffe nach L√§nge (l√§ngste zuerst) um √úberlappungen zu vermeiden
    sorted_terms = sorted(search_terms, key=len, reverse=True)
    
    for term in sorted_terms:
        if term and len(term.strip()) > 1:  # Nur nicht-leere Begriffe mit mehr als 1 Zeichen
            # Bestimme Farbe basierend darauf, ob es ein urspr√ºnglicher Begriff ist
            is_original = any(orig_term.lower() in term.lower() or term.lower() in orig_term.lower() 
                            for orig_term in original_query_terms)
            
            if is_original:
                # Gelb f√ºr urspr√ºngliche Suchbegriffe
                color_style = 'background-color: #ffeb3b; padding: 2px 4px; border-radius: 3px;'
            else:
                # Orange f√ºr KI-erweiterte Begriffe
                color_style = 'background-color: #ff9800; color: white; padding: 2px 4px; border-radius: 3px;'
            
            # Case-insensitive Ersetzung mit HTML-Markierung
            pattern = re.compile(re.escape(term.strip()), re.IGNORECASE)
            highlighted_text = pattern.sub(f'<mark style="{color_style}">{term.strip()}</mark>', highlighted_text)
    
    return highlighted_text


def extract_context_around_terms(text, search_terms, max_lines=9):
    """Extrahiert relevanten Kontext um Suchbegriffe herum und limitiert auf max_lines."""
    import re
    
    if not search_terms:
        lines = text.split('\n')
        return '\n'.join(lines[:max_lines]) + ('...' if len(lines) > max_lines else '')
    
    # Finde alle Positionen der Suchbegriffe
    positions = []
    for term in search_terms:
        if term and len(term.strip()) > 1:
            for match in re.finditer(re.escape(term.strip()), text, re.IGNORECASE):
                positions.append(match.start())
    
    if not positions:
        lines = text.split('\n')
        return '\n'.join(lines[:max_lines]) + ('...' if len(lines) > max_lines else '')
    
    # Finde die beste Position f√ºr den Kontext (erste Fundstelle)
    best_pos = min(positions)
    
    # Extrahiere Kontext um diese Position
    context_start = max(0, best_pos - 300)
    context_end = min(len(text), best_pos + 700)
    context = text[context_start:context_end]
    
    # Auf Zeilenbasis begrenzen
    lines = context.split('\n')
    if len(lines) > max_lines:
        # Versuche die relevanteste Stelle zu finden
        relevant_lines = []
        for i, line in enumerate(lines):
            line_has_term = any(term.lower() in line.lower() for term in search_terms if term and len(term.strip()) > 1)
            if line_has_term or len(relevant_lines) < max_lines:
                relevant_lines.append(line)
            if len(relevant_lines) >= max_lines:
                break
        context = '\n'.join(relevant_lines)
        if len(lines) > max_lines:
            context += '...'
    
    # Pr√§fix/Suffix hinzuf√ºgen wenn Text abgeschnitten wurde
    if context_start > 0:
        context = '...' + context
    if context_end < len(text):
        context = context + '...'
    
    return context


def search_text_in_pdf(pdf_path, search_terms, page_range):
    """Durchsucht eine PDF nach einer Liste von exakten Begriffen (Einfache Suche)."""
    ergebnisse = []
    try:
        doc = fitz.open(pdf_path)
        start_page, end_page = page_range
        
        print(f"DEBUG: Einfache Suche nach Begriffen: {search_terms}")
        print(f"DEBUG: Seitenbereich: {start_page+1} bis {end_page}")
        
        for page_num in range(start_page, end_page):
            page = doc.load_page(page_num)
            text = page.get_text("text")
            
            if not text.strip():
                continue
                
            # Suche nach jedem Begriff einzeln
            found_terms = []
            for term in search_terms:
                if term.strip() and term.lower() in text.lower():
                    found_terms.append(term)
            
            if found_terms:
                print(f"DEBUG: Seite {page_num + 1}, gefundene Begriffe: {found_terms}")
                
                # Extrahiere relevanten Kontext um die gefundenen Begriffe
                context_snippet = extract_context_around_terms(text, found_terms, max_lines=9)
                
                # Falls kein spezifischer Kontext gefunden, verwende Standard-Snippet
                if not context_snippet.strip():
                    first_term = found_terms[0]
                    pos = text.lower().find(first_term.lower())
                    start = max(0, pos - 100)
                    end = min(len(text), pos + len(first_term) + 400)
                    context_snippet = text[start:end]
                    if start > 0: 
                        context_snippet = "..." + context_snippet
                    if end < len(text): 
                        context_snippet = context_snippet + "..."
                
                # Hervorhebung der gefundenen Suchbegriffe (bei einfacher Suche sind alle urspr√ºnglich)
                highlighted_snippet = highlight_terms_in_text(context_snippet, found_terms, found_terms)
                
                ergebnisse.append({
                    'seitenzahl': page_num + 1, 
                    'textstelle': context_snippet,
                    'textstelle_highlighted': highlighted_snippet,
                    'found_terms': found_terms
                })
        
        doc.close()
        print(f"DEBUG: Einfache Suche abgeschlossen. {len(ergebnisse)} Ergebnisse gefunden.")
        
    except Exception as e:
        print(f"Fehler bei der einfachen PDF-Suche: {e}")
        
    return ergebnisse


def pdf_suche(request):
    """Hauptansicht f√ºr die PDF-Suche."""
    if request.method == "POST":
        step = request.POST.get("step", "initial")
        search_type = request.POST.get("search_type")
        search_perspective = request.POST.get("search_perspective", "sales")
        suchanfrage = request.POST.get("suchanfrage")
        pdf_file = request.FILES.get("pdf_datei")
        seite_von_str = request.POST.get("seite_von")
        seite_bis_str = request.POST.get("seite_bis")

        # Schritt 1: Initiale Suche - Zeige erweiterte Begriffe f√ºr KI-Suche
        if step == "initial" and search_type == "ai":
            if not pdf_file:
                return render(request, "pdf_sucher/suche.html",
                              {"step": "initial", "error_message": "Bitte eine PDF-Datei hochladen."})
            
            # Speichere PDF tempor√§r
            fs = FileSystemStorage(location=os.path.join(settings.MEDIA_ROOT, "pdfs"))
            filename = secure_filename(pdf_file.name)
            base, extension = os.path.splitext(filename)
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            unique_filename = f"{base}_{timestamp}{extension}"
            pdf_filename = fs.save(unique_filename, pdf_file)
            
            # Validiere Seitenbereich
            try:
                doc = fitz.open(fs.path(pdf_filename))
                start_page = int(seite_von_str) - 1 if seite_von_str.isdigit() else 0
                end_page = int(seite_bis_str) if seite_bis_str.isdigit() else len(doc)
                doc.close()
            except Exception as e:
                return render(request, "pdf_sucher/suche.html",
                              {"step": "initial", "error_message": f"PDF konnte nicht verarbeitet werden: {e}"})
            
            # Generiere erweiterte Suchbegriffe
            expanded_terms = expand_search_terms_with_ai(suchanfrage, search_perspective)
            
            context = {
                'step': 'preview_terms',
                'pdf_filename': pdf_filename,
                'suchanfrage': suchanfrage,
                'search_type': search_type,
                'search_perspective': search_perspective,
                'seite_von': seite_von_str,
                'seite_bis': seite_bis_str,
                'expanded_terms': expanded_terms,
                'original_terms': [term.strip() for term in suchanfrage.split() if len(term.strip()) > 1]
            }
            return render(request, "pdf_sucher/suche.html", context)
        
        # Schritt 2: F√ºhre die eigentliche Suche durch
        if step == "search" or search_type == "simple":
            # F√ºr einfache Suche oder wenn erweiterte Begriffe bereits ausgew√§hlt wurden
            pdf_filename = request.POST.get("pdf_filename")
            if not pdf_filename:
                if not pdf_file:
                    return render(request, "pdf_sucher/suche.html",
                                  {"step": "initial", "error_message": "Bitte eine PDF-Datei hochladen."})
                
                fs = FileSystemStorage(location=os.path.join(settings.MEDIA_ROOT, "pdfs"))
                filename = secure_filename(pdf_file.name)
                base, extension = os.path.splitext(filename)
                timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                unique_filename = f"{base}_{timestamp}{extension}"
                pdf_filename = fs.save(unique_filename, pdf_file)
            
            pdf_path = os.path.join(settings.MEDIA_ROOT, "pdfs", pdf_filename)

            try:
                doc = fitz.open(pdf_path)
                start_page = int(seite_von_str) - 1 if seite_von_str.isdigit() else 0
                end_page = int(seite_bis_str) if seite_bis_str.isdigit() else len(doc)
                page_range = (max(0, start_page), min(len(doc), end_page))
                doc.close()
            except Exception as e:
                return render(request, "pdf_sucher/suche.html",
                              {"step": "initial", "error_message": f"PDF konnte nicht verarbeitet werden: {e}"})

            ergebnisse = []
            if search_type == 'ai':
                strictness_value_str = request.POST.get('ai_strictness', '50')
                try:
                    strictness_value = float(strictness_value_str)
                except (ValueError, TypeError):
                    strictness_value = 50.0

                # Umrechnung des Regler-Wertes (0-100) in einen Schwellenwert (0.1 - 0.8)
                # Niedrigere Werte = weniger streng, mehr Ergebnisse
                similarity_threshold = 0.1 + (strictness_value / 100.0) * 0.7
                print(f"DEBUG: Strenge-Wert: {strictness_value}, Schwellenwert: {similarity_threshold:.3f}")

                # Sammle ausgew√§hlte erweiterte Begriffe
                selected_expanded_terms = []
                if step == "search":
                    # Hole alle ausgew√§hlten erweiterten Begriffe aus den Checkboxes
                    for key, value in request.POST.items():
                        if key.startswith('expanded_term_'):
                            # Der Wert der Checkbox ist der Begriff selbst
                            selected_expanded_terms.append(value)
                    
                    print(f"DEBUG: Ausgew√§hlte erweiterte Begriffe: {selected_expanded_terms}")

                ergebnisse = perform_semantic_search_with_selected_terms(
                    pdf_path, suchanfrage, page_range, similarity_threshold, 
                    search_perspective, selected_expanded_terms
                )

            elif search_type == 'simple':
                search_terms = [term.strip() for term in suchanfrage.split(",")]
                ergebnisse = search_text_in_pdf(pdf_path, search_terms, page_range)

            # Suchbegriffe f√ºr die Vorschau vorbereiten
            if search_type == 'simple':
                search_terms_for_preview = search_terms
            else:  # AI-Suche - Verwende die erweiterten Begriffe falls verf√ºgbar
                search_terms_for_preview = []
                if ergebnisse:
                    # Sammle alle gefundenen Begriffe aus den Ergebnissen
                    for ergebnis in ergebnisse:
                        if 'found_terms' in ergebnis:
                            search_terms_for_preview.extend(ergebnis['found_terms'])
                    # Entferne Duplikate
                    search_terms_for_preview = list(set(search_terms_for_preview))
                
                # Fallback: Verwende urspr√ºngliche Query-Begriffe
                if not search_terms_for_preview:
                    search_terms_for_preview = [term.strip() for term in suchanfrage.split() if len(term.strip()) > 2]
            
            # Generiere PDF mit Suchergebnissen
            results_pdf_filename = None
            if ergebnisse:
                print(f"DEBUG: Generiere PDF mit {len(ergebnisse)} Ergebnissen")
                results_pdf_filename = generate_search_results_pdf(
                    pdf_path, ergebnisse, suchanfrage, search_type, search_perspective
                )
                print(f"DEBUG: PDF erstellt: {results_pdf_filename}")
            else:
                print("DEBUG: Keine Ergebnisse f√ºr PDF-Generierung")
            
            # Sammle alle erweiterten Begriffe f√ºr die Anzeige
            expanded_terms_for_display = []
            if search_type == 'ai' and ergebnisse:
                # Versuche die erweiterten Begriffe aus dem ersten Ergebnis zu holen
                try:
                    expanded_terms_for_display = expand_search_terms_with_ai(suchanfrage, search_perspective)
                except:
                    expanded_terms_for_display = []
            
            context = {
                'step': 'results',
                'ergebnisse': ergebnisse,
                'pdf_filename': pdf_filename,
                'results_pdf_filename': results_pdf_filename,
                'search_terms': ','.join(search_terms_for_preview),
                'search_type': search_type,
                'search_perspective': search_perspective,
                'suchanfrage': suchanfrage,
                'expanded_terms': expanded_terms_for_display,
            }
            print(f"DEBUG: Context f√ºr Template - results_pdf_filename: {results_pdf_filename}")
            print(f"DEBUG: Context f√ºr Template - ergebnisse: {len(ergebnisse) if ergebnisse else 0}")
            return render(request, "pdf_sucher/suche.html", context)

    return render(request, "pdf_sucher/suche.html", {"step": "initial"})


def view_pdf(request, filename):
    pdf_path = os.path.join(settings.MEDIA_ROOT, "pdfs", filename)
    if os.path.exists(pdf_path):
        return FileResponse(open(pdf_path, "rb"), content_type="application/pdf")
    raise Http404("PDF nicht gefunden")


def highlight_context_in_pdf_page(page, context_text, highlight_color=[1, 1, 0]):
    """Hebt den gefundenen Kontext im PDF hervor basierend auf dem extrahierten Text."""
    import re
    
    if not context_text or not context_text.strip():
        return
    
    # Bereinige den Kontext-Text von Markierungen und extrahiere relevante Phrasen
    clean_context = re.sub(r'<[^>]+>', '', context_text)  # Entferne HTML-Tags
    clean_context = clean_context.replace('...', '').strip()  # Entferne Ellipsen
    
    # Extrahiere bedeutungsvolle Phrasen (mindestens 3 W√∂rter zusammen)
    words = clean_context.split()
    phrases = []
    
    # Erstelle Phrasen verschiedener L√§ngen
    for length in [5, 4, 3]:  # L√§ngere Phrasen zuerst
        for i in range(len(words) - length + 1):
            phrase = ' '.join(words[i:i+length])
            if len(phrase.strip()) > 10:  # Mindestl√§nge f√ºr Phrasen
                phrases.append(phrase.strip())
    
    # F√ºge auch einzelne wichtige W√∂rter hinzu (l√§nger als 4 Zeichen)
    for word in words:
        if len(word) > 4 and word.isalpha():
            phrases.append(word)
    
    # Entferne Duplikate und sortiere nach L√§nge
    phrases = sorted(list(set(phrases)), key=len, reverse=True)
    
    highlighted_count = 0
    max_highlights = 10  # Begrenze die Anzahl der Hervorhebungen
    
    for phrase in phrases:
        if highlighted_count >= max_highlights:
            break
            
        # Suche nach der Phrase im PDF
        text_instances = page.search_for(phrase)
        if text_instances:
            for inst in text_instances:
                # Orange Hervorhebung f√ºr Kontext (unterschiedlich von gelb f√ºr Suchbegriffe)
                highlight = page.add_highlight_annot(inst)
                highlight.set_colors({"stroke": [1, 0.65, 0]})  # Orange
                highlight.update()
                highlighted_count += 1
                if highlighted_count >= max_highlights:
                    break
            break  # Stoppe nach der ersten erfolgreichen Phrase


def generate_search_results_pdf(original_pdf_path, search_results, search_query, search_type, search_perspective=None):
    """Erstellt eine PDF mit den Suchergebnissen und Links zu den Fundstellen."""
    try:
        print(f"DEBUG: PDF-Generierung gestartet f√ºr {len(search_results)} Ergebnisse")
        # Erstelle tempor√§re Datei f√ºr die Ergebnis-PDF
        temp_filename = f"suchergebnisse_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        temp_path = os.path.join(settings.MEDIA_ROOT, "pdfs", temp_filename)
        
        # √ñffne das Original-PDF
        original_doc = fitz.open(original_pdf_path)
        
        # Erstelle eine Kopie des Original-PDFs
        result_doc = fitz.open()
        result_doc.insert_pdf(original_doc)
        
        # Erstelle eine neue Seite f√ºr die Suchergebnisse am ANFANG der PDF
        results_page = result_doc.new_page(0, width=595, height=842)  # A4 Format, Position 0 = am Anfang
        
        # Text-Inhalt f√ºr die Ergebnisseite (Koordinaten von oben nach unten)
        y_position = 50  # Start von oben (50pt Abstand vom oberen Rand)
        
        # Titel
        results_page.insert_text((50, y_position), "Suchergebnisse", fontsize=20, color=(0, 0, 0))
        y_position += 40
        
        # Suchdetails
        results_page.insert_text((50, y_position), f"Suchanfrage: {search_query}", fontsize=12, color=(0, 0, 0))
        y_position += 20
        
        search_type_text = "KI-gest√ºtzte Kontextsuche" if search_type == "ai" else "Einfache Textsuche"
        results_page.insert_text((50, y_position), f"Suchmethode: {search_type_text}", fontsize=12, color=(0, 0, 0))
        y_position += 20
        
        if search_type == "ai" and search_perspective:
            perspective_text = "Vertriebsmitarbeiter" if search_perspective == "sales" else "Entwickler/Techniker"
            results_page.insert_text((50, y_position), f"Perspektive: {perspective_text}", fontsize=12, color=(0, 0, 0))
            y_position += 20
        
        results_page.insert_text((50, y_position), f"Gefundene Ergebnisse: {len(search_results)}", fontsize=12, color=(0, 0, 0))
        y_position += 20
        
        # Hinweis f√ºr Navigation
        results_page.insert_text((50, y_position), "Navigation: Nutzen Sie die Seitenzahlen in der √úbersicht unten f√ºr manuelle Navigation", fontsize=10, color=(0.5, 0.5, 0.5))
        y_position += 30
        
        # Erstelle ein einfaches Inhaltsverzeichnis
        results_page.insert_text((50, y_position), "Schnell√ºbersicht:", fontsize=14, color=(0, 0, 0))
        y_position += 25
        
        # Liste alle Ergebnisse mit Seitenzahlen auf
        for i, result in enumerate(search_results[:10]):  # Maximal 10 f√ºr √úbersicht
            page_ref = result['seitenzahl']
            results_page.insert_text((70, y_position), f"‚Ä¢ Ergebnis {i+1} ‚Üí Seite {page_ref}", fontsize=11, color=(0, 0, 0))
            y_position += 18
        
        if len(search_results) > 10:
            results_page.insert_text((70, y_position), f"... und {len(search_results)-10} weitere Ergebnisse", fontsize=11, color=(0.5, 0.5, 0.5))
            y_position += 18
            
        y_position += 20
        
        # Ergebnisse auflisten mit korrekter Seitenverwaltung
        print(f"DEBUG: Beginne mit der Erstellung von {len(search_results)} Ergebnissen")
        
        for i, result in enumerate(search_results):  # Alle Ergebnisse
            print(f"DEBUG: Verarbeite Ergebnis {i+1}/{len(search_results)}")
            
            # Pr√ºfe ob genug Platz f√ºr das gesamte Ergebnis (ca. 100pt ben√∂tigt)
            if y_position > 720:  # Sicherheitsabstand zum Seitenende (842pt - 120pt = 720pt)
                print(f"DEBUG: Erstelle neue Seite bei y_position {y_position}")
                results_page = result_doc.new_page(width=595, height=842)
                y_position = 50  # Wieder von oben anfangen
            
            # Ergebnis-Header 
            page_num = result['seitenzahl']
            results_page.insert_text((50, y_position), f"Ergebnis {i+1}: Seite {page_num}", fontsize=14, color=(0, 0, 1))
            
            # Versuche verschiedene Link-Ans√§tze
            header_rect = fitz.Rect(50, y_position-2, 250, y_position+16)
            target_page = page_num  # Korrekte Seite da wir am Anfang einf√ºgen
            
            # Erstelle Lesezeichen f√ºr bessere Navigation
            try:
                # Erstelle Lesezeichen zur Original-Seite
                toc_entry = [1, f"Ergebnis {i+1} (Seite {page_num})", target_page]
                if not hasattr(result_doc, '_bookmarks'):
                    result_doc._bookmarks = []
                result_doc._bookmarks.append(toc_entry)
                print(f"DEBUG: Lesezeichen f√ºr Seite {page_num} erstellt")
            except Exception as bookmark_error:
                print(f"DEBUG: Lesezeichen-Erstellung fehlgeschlagen: {bookmark_error}")
            
            # Versuche robuste Link-Erstellung
            try:
                # Einfachster m√∂glicher Link-Ansatz
                if 0 <= target_page < len(result_doc):
                    link_dict = {"kind": fitz.LINK_GOTO, "page": target_page}
                    results_page.insert_link(link_dict, header_rect)
                    print(f"DEBUG: Einfacher Link zu Seite {page_num} erstellt")
                    
                    # Visueller Hinweis f√ºr funktionierende Links
                    results_page.draw_rect(header_rect, color=(0, 0, 1), width=2)
                    results_page.insert_text(
                        (255, y_position), 
                        "üìÑ ‚Üê KLICK", 
                        fontsize=10, 
                        color=(0, 0, 1)
                    )
                else:
                    print(f"DEBUG: Ung√ºltige Seitenzahl {target_page}")
                    
            except Exception as link_error:
                print(f"DEBUG: Link-Erstellung fehlgeschlagen: {link_error}")
                # Fallback: Nur visueller Hinweis
                results_page.draw_rect(header_rect, color=(0.5, 0.5, 0.5), width=1)
                results_page.insert_text(
                    (255, y_position), 
                    f"(‚Üí Seite {page_num})", 
                    fontsize=10, 
                    color=(0.5, 0.5, 0.5)
                )
            
            y_position += 25
            
            # Textausschnitt (ohne HTML-Tags)
            import re
            result_text = result.get('textstelle', '')
            if isinstance(result_text, str):
                clean_text = re.sub(r'<[^>]+>', '', result_text)
                clean_text = clean_text[:400] + "..." if len(clean_text) > 400 else clean_text
            else:
                clean_text = "Kein Text verf√ºgbar"
            
            # Teile langen Text in mehrere Zeilen auf
            max_chars_per_line = 75
            words = clean_text.split()
            lines = []
            current_line = ""
            
            for word in words:
                if len(current_line + " " + word) <= max_chars_per_line:
                    current_line += " " + word if current_line else word
                else:
                    if current_line:
                        lines.append(current_line)
                    current_line = word
            if current_line:
                lines.append(current_line)
            
            # Zeige maximal 5 Zeilen pro Ergebnis
            lines_shown = 0
            for line in lines[:5]:
                if y_position > 800:  # Notfall-Seitenende
                    print(f"DEBUG: Seitenende erreicht bei Zeile {lines_shown}")
                    break
                results_page.insert_text((70, y_position), line, fontsize=10, color=(0.3, 0.3, 0.3))
                y_position += 15
                lines_shown += 1
            
            y_position += 15  # Extra Abstand zwischen Ergebnissen
            print(f"DEBUG: Ergebnis {i+1} abgeschlossen, y_position: {y_position}")
        
        print(f"DEBUG: Alle {len(search_results)} Ergebnisse verarbeitet")
        
        # F√ºge Lesezeichen zur PDF hinzu (falls welche erstellt wurden)
        try:
            if hasattr(result_doc, '_bookmarks') and result_doc._bookmarks:
                result_doc.set_toc(result_doc._bookmarks)
                print(f"DEBUG: {len(result_doc._bookmarks)} Lesezeichen zur PDF hinzugef√ºgt")
        except Exception as toc_error:
            print(f"DEBUG: Lesezeichen konnten nicht hinzugef√ºgt werden: {toc_error}")
        
        # Speichere die neue PDF mit optimierten Einstellungen
        result_doc.save(temp_path, 
                       garbage=4,     # Optimiert die PDF
                       clean=True,    # Bereinigt die PDF
                       deflate=True   # Komprimiert die PDF
                       )
        result_doc.close()
        original_doc.close()
        
        print(f"DEBUG: PDF erfolgreich erstellt: {temp_filename}")
        
        # √úberpr√ºfe ob die PDF-Datei tats√§chlich erstellt wurde
        if os.path.exists(temp_path):
            file_size = os.path.getsize(temp_path)
            print(f"DEBUG: PDF-Datei existiert, Gr√∂√üe: {file_size} Bytes")
        else:
            print(f"DEBUG: WARNUNG - PDF-Datei wurde nicht erstellt!")
            
        return temp_filename
        
    except Exception as e:
        print(f"FEHLER bei der PDF-Generierung: {e}")
        return None


def pdf_page_preview(request, filename, page_num):
    pdf_path = os.path.join(settings.MEDIA_ROOT, "pdfs", filename)
    if not os.path.exists(pdf_path):
        raise Http404("PDF nicht gefunden")
    
    # Suchbegriffe aus GET-Parameter extrahieren
    search_terms = request.GET.get('search_terms', '').split(',') if request.GET.get('search_terms') else []
    search_terms = [term.strip() for term in search_terms if term.strip()]
    
    # Kontext-Text f√ºr KI-Suche extrahieren
    context_text = request.GET.get('context_text', '')
    search_type = request.GET.get('search_type', 'simple')
    
    try:
        doc = fitz.open(pdf_path)
        if 0 < page_num <= len(doc):
            page = doc.load_page(page_num - 1)
            
            # Hervorhebung der Suchbegriffe auf der PDF-Seite (gelb)
            if search_terms:
                for term in search_terms:
                    if term and len(term.strip()) > 1:  # Nur nicht-leere Begriffe
                        # Finde alle Vorkommen des Begriffs auf der Seite
                        text_instances = page.search_for(term.strip())
                        for inst in text_instances:
                            # Gelbe Hervorhebung hinzuf√ºgen
                            highlight = page.add_highlight_annot(inst)
                            highlight.set_colors({"stroke": [1, 1, 0]})  # Gelb
                            highlight.update()
            
            # Zus√§tzliche Kontext-Hervorhebung f√ºr KI-Suche (orange)
            if search_type == 'ai' and context_text:
                highlight_context_in_pdf_page(page, context_text)
            
            pix = page.get_pixmap(dpi=150)
            img_byte_arr = io.BytesIO()
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            img.save(img_byte_arr, format="PNG")
            img_byte_arr.seek(0)
            doc.close()
            return HttpResponse(img_byte_arr, content_type="image/png")
        else:
            raise Http404("Seite nicht gefunden")
    except Exception as e:
        print(f"Fehler bei der Vorschauerstellung: {e}")
        raise Http404("Vorschau konnte nicht erstellt werden")